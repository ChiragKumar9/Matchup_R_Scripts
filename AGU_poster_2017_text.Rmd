---
title: "Estimates of Single Sensor Error Statistics for the MODIS Matchup Database Using Machine Learning"
author: "Chirag Kumar and Guillermo Podesta"
output:
  html_notebook:
    toc: True
    theme: united
---


```{r prep_workspace, echo=FALSE}
# See NLSST_exploration_and_trees_AGU_2017
```

# Introduction

* NASA: SST = single most important indicator of Climate Change
* Buoys = accurate
    + Not global or repeated
* Sensors aboard satellites
    + Global and repeated
    + Measures Top of Atmosphere Brightness Temperatures
    + Matchups + Atmospheric Correction: TOA BTs --> SST estimate

# Motivation

* High SSTs, measures of atmospheric absorption stop responding proportionally to actual atmospheric absorption
* Attempts to fix this in Atmospheric Correction: multiplying measures of atmospheric absorption by reference SST
but problem still persists

```{r product_temp_deficit, echo=FALSE}
# --- These numbers may help perform statistics for the matchups
# --- (e.g., number of matchups per cell, etc.).

temp_deficit_est <- orig$ref_SST - orig$T_11
temp_deficit <- orig$buoy.sst - orig$T_11

uuu <- data.frame(resid_context = as.factor(resid_context), temp_deficit_est = temp_deficit_est, product = (orig$band.diff * orig$ref_SST),
                  temp_deficit = temp_deficit,
                  SST.resid.SMB = orig$SST.resid.SMB)

# Take a sample of uuu bc loess requires lots of memory - for testing purposes
set.seed(42)
index <- sample(1:nrow(uuu), 50000, replace = FALSE)
uuu <- uuu[index, ]

# --- Create a raster object with 5-degree pixels

grid5deg <- raster::raster(ncol = 20, nrow = 20,
  xmn = min(uuu$product) - 0.1, xmx = max(uuu$product) + 0.1,
  ymn = min(uuu$temp_deficit) - 0.1, ymx = max(uuu$temp_deficit) + 0.1)
  #crs = crs.string)

# --- Write cell numbers as value for the grids.
# --- Cell 1 is the upper left corner and numbers go
# --- across the top line through its end, then
# --- start again in the second line, and so forth.

raster::values(grid5deg) <- 1:raster::ncell(grid5deg) # Cell numbers for 5 deg grid

raster::cellFromRowCol(object = grid5deg, rownr = 2, colnr = 20)

raster::xyFromCell(object =  grid5deg, cell = 800, spatial = FALSE)

pts <- data.frame(product = uuu$product, temp_deficit = uuu$temp_deficit)
SST.resid.SMB <- uuu$SST.resid.SMB

count_resids <- function(residuals, ...) {
  return(length(residuals))
}

cell5deg <- raster::rasterize(pts, grid5deg, SST.resid.SMB, fun = count_resids)

ccc <- RColorBrewer::brewer.pal(n = 9, 'YlOrRd')
ccc <- ccc[3:9]

breaks <- c(0, 50, 100, 250, 500, 1000, 2500, 5000, Inf)

# Add loess and linear fits
Xs <- data.frame(Xs = seq(from = 0, to = 140, by = .3505))

td_lm <- lm(uuu$temp_deficit ~ uuu$product)
lm_estimates <- td_lm$coefficients[1] + (td_lm$coefficients[2] * Xs)
lm_estimates <- as.vector(lm_estimates$Xs)

td_loess <- loess(temp_deficit ~ product, data = uuu, span = 0.4)
loess_estimates <- predict(td_loess, newdata = Xs$Xs)

rasterVis::gplot(cell5deg) + 
  ggplot2::geom_raster(aes(fill = (cut(value, breaks)))) +
  scale_fill_manual(values = ccc) +
  geom_line(aes(x = Xs, y = lm_estimates), color = 'green') +
  geom_line(aes(x = Xs, y = loess_estimates), color = 'blue') +
  #scale_fill_gradientn(colours = palette) +
  labs(x = '(T_11 - T_12) * Reference SST', y = 'Temperature Deficit', fill = '# of Retrievals') +
  coord_fixed(ratio = 2.4) +
  xlim(-2, 122) +
  ylim(-.1, 22)
```

Caption: Figure 1: The green line represents a linear fit to the data while the blue curve is the loess fit.

* Loess = non-parametric, shows the true shape of data
    + locally fits a line to subset of the data then smooths all the lines
* Significant loss of linearity/proportionality at high SSTs (high values of the product)
    + Deviation the loess fit shows from the linear fit

* However, non-linearity at high SSTs doesn't always lead to an error or residual
(satellite SST minus buoy SST)

```{r band_diff_temp_deficit_cumulative_contours, echo=FALSE}

# data:
resid_context <- cut(orig$SST.resid.SMB, c(-Inf, -.4, .4, Inf))
temp_deficit <- orig$buoy.sst - orig$T_11

uuu <- data.frame(resid_context = as.factor(resid_context), temp_deficit = temp_deficit, product = (orig$band.diff * orig$ref_SST))

# Take a sample of uuu bc loess requires lots of memory - for testing purposes
set.seed(42)
index <- sample(1:nrow(uuu), 50000, replace = FALSE)
uuu <- uuu[index, ]

# filter - create two dataframes, good vs bad residuals

uuu_good <- dplyr::tbl_df(uuu) %>%
  dplyr::filter(resid_context == '(-0.4,0.4]')

uuu_bad <- dplyr::tbl_df(uuu) %>%
  dplyr::filter(resid_context == '(-Inf,-0.4]')

uuu_good <- as.data.frame(uuu_good)
uuu_bad <- as.data.frame(uuu_bad)

# get the kde2d information:
# for good
uuu_good.kde <- kde2d(uuu_good[,2], uuu_good[,3], n = 400)
dx_good <- diff(uuu_good.kde$x[2:3])  # lifted from emdbook::HPDregionplot()
dy_good <- diff(uuu_good.kde$y[2:3])
sz_good <- sort(uuu_good.kde$z)
c1_good <- cumsum(sz_good) * dx_good * dy_good

# for bad
uuu_bad.kde <- kde2d(uuu_bad[,2], uuu_bad[,3], n = 400)
dx_bad <- diff(uuu_bad.kde$x[2:3])  # lifted from emdbook::HPDregionplot()
dy_bad <- diff(uuu_bad.kde$y[2:3])
sz_bad <- sort(uuu_bad.kde$z)
c1_bad <- cumsum(sz_bad) * dx_bad * dy_bad

# specify desired contour levels:
prob <- c(0.25, 0.5, 0.75, 0.90, 0.999)

# Configure plot
# for good
dimnames(uuu_good.kde$z) <- list(uuu_good.kde$x, uuu_good.kde$y)
dc_good <- melt(uuu_good.kde$z)
dc_good$prob <- approx(sz_good, 1 - c1_good, dc_good$value)$y

# for bad
dimnames(uuu_bad.kde$z) <- list(uuu_bad.kde$x, uuu_bad.kde$y)
dc_bad <- melt(uuu_bad.kde$z)
dc_bad$prob <- approx(sz_bad, 1 - c1_bad, dc_bad$value)$y

dc_good$residual <- '(-0.4,0.4]'
dc_bad$residual <- '(-Inf,-0.4]'
dc <- rbind(dc_good, dc_bad)

class_colors <- c('(-0.4,0.4]' = '#00BFC4', '(-Inf,-0.4]' = '#F8766D')

# Actual plot
p <- ggplot2::ggplot() +
  geom_contour(data = dc, aes(x = Var2, y = Var1, z = prob, color = residual), breaks = prob) +
  #geom_contour(data = dc_bad, aes(x = Var2, y = Var1, z = prob), breaks = prob, color = '#F8766D') + , color = '#00BFC4'
  labs(x = '(T_11 - T_12) * Reference SST', y = 'Temperature Deficit', color = 'Residual Range') +
  coord_fixed(ratio = 2.4) +
  xlim(-2, 122) +
  ylim(-.1, 22) + 
  scale_color_manual(values = class_colors)

print(p)

```

Caption: Figure 2: Contours are drawn around 25, 50, 75, and 99.9% of the data. 

* High SSTs = higher chance of having negative residual
    + Not always
* Even at lower SSTs, significant overlap between retrievals of varying residual magnitudes
    + Difficult to separate low residual retrievals from high residual retrievals
  
# Problem Statement/Question/Proposal
Using Machine Learning to gain intuition for our data, we aim to understand what combinations of 
geophysical condtions affect residual magnitude specifically in warm SST environments and ultimately
precisely and accurately numerically quantify the SST residual.

# Data

* MODIS onboard NASA's Aqua
* LWIR ($\lambda$ = 10 - 12 $\mu$m)
* Only night-time data to remove sun effects such as diurnal warming and sun glint contamination
* QSST = 0, 1, 2
* Remove any matchup with residual > 0.4
    + Very abnormal, probably pre-flagged and identified
* `r nrow(orig)` matchups

# Results

* Classes
    + "Good" = -0.4 < residual $\leq$ 0.4
    + "Bad" = residual $\leq$ -0.4
* Divide data into 60% trains and 40% test sets
* No scaling - doesn't improve decision tree convergence
    
```{r binning_retrievals_band_diff_temp_def_residual_a_la_raster, echo=FALSE}
# --- These numbers may help perform statistics for the matchups
# --- (e.g., number of matchups per cell, etc.).

temp_deficit_est <- orig$ref_SST - orig$T_11
temp_deficit <- orig$buoy.sst - orig$T_11

uuu <- data.frame(resid_context = as.factor(resid_context), temp_deficit_est = temp_deficit_est, product = (orig$band.diff * orig$ref_SST),
                  temp_deficit = temp_deficit,
                  x3 = orig$x3,
                  sec_satz = secant.deg(orig$satz),
                  SST.resid.SMB = orig$SST.resid.SMB)

# Take a sample of uuu bc loess requires lots of memory - for testing purposes
set.seed(42)
index <- sample(1:nrow(uuu), 50000, replace = FALSE)
uuu <- uuu[index, ]

# Horizontalize
td_estimate_fit <- predict(td_loess, newdata = uuu$product)
uuu$td_fit_error <- uuu$temp_deficit_est - td_estimate_fit

# --- Create a raster object with 5-degree pixels

grid5deg <- raster::raster(ncol = 20, nrow = 20,
  xmn = min(uuu$product) - 0.1, xmx = max(uuu$product) + 0.1,
  ymn = min(uuu$temp_deficit) - 0.1, ymx = max(uuu$temp_deficit) + 0.1)
  #crs = crs.string)

# --- Write cell numbers as value for the grids.
# --- Cell 1 is the upper left corner and numbers go
# --- across the top line through its end, then
# --- start again in the second line, and so forth.

raster::values(grid5deg) <- 1:raster::ncell(grid5deg) # Cell numbers for 5 deg grid

raster::cellFromRowCol(object = grid5deg, rownr = 2, colnr = 20)

raster::xyFromCell(object =  grid5deg, cell = 800, spatial = FALSE)

pts <- data.frame(product = uuu$product, temp_deficit = uuu$temp_deficit)
SST.resid.SMB <- uuu$SST.resid.SMB

count_good_residuals <- function(residuals, ...) {
  #if (length(residuals) < 82) {
  #  return(-Inf)
  #}
  resid_cats <- cut(residuals, c(-Inf, -0.4, 0.4))
  N_resid_bad_low <- table(resid_cats)[1]
  N_resid_good <- table(resid_cats)[2]
  fraction_good <- N_resid_good / (N_resid_bad_low + N_resid_good)
  return(fraction_good)
}

cell5deg <- raster::rasterize(pts, grid5deg, SST.resid.SMB, fun = count_good_residuals) # fun can be median, IQR, or count_good_residuals

#qqq <- dplyr::tbl_df(uuu) %>%
#  dplyr::group_by(cell5deg) %>%
#  dplyr::summarise(N = n(), med = median(SST.resid.SMB), IQR = IQR(SST.resid.SMB)) %>%
#  dplyr::filter(N >= 100)

#qq1 <- rep(NA, (20*40))
#qq1[qqq$cell5deg] <- qqq$med

#raster::values(grid5deg) <- qq1

blues_palette <- rev(RColorBrewer::brewer.pal(9, 'Blues'))
blues_palette <- colorRampPalette(blues_palette)(4)

reds_palette <- RColorBrewer::brewer.pal(9, 'Reds')
reds_palette <- colorRampPalette(reds_palette)(4)

palette <- c(blues_palette, '#f0f0f0', '#f0f0f0', reds_palette)
palette <- rev(palette)


ccc <- RColorBrewer::brewer.pal(n = 9, 'YlOrRd')
ccc <- ccc[3:9]

#rasterVis::levelplot(cell5deg, margin = FALSE,
#  at = c(-Inf, seq(from = 0, to = 1.0, by = 0.05), Inf),
#  col.regions = palette,
#  xlab = '(T_11 - T_12) * Reference SST',
#  ylab = 'Temperature Deficit')

breaks <- seq(from = 0, to = 1, by = 0.1)

rasterVis::gplot(cell5deg) + 
  ggplot2::geom_raster(aes(fill = (cut(value, breaks)))) +
  scale_fill_manual(values = palette) +
  #scale_fill_gradientn(colours = palette) +
  labs(x = '(T_11 - T_12) * Reference SST', y = 'Temperature Deficit', fill = 'Fraction of\nGood Retrievals') +
  coord_fixed(ratio = 2.4) +
  xlim(-2, 122) +
  ylim(-.1, 22)
```

Caption: Figure 3: (???CAPTION???)

* Distinct areas of high probabilities of low/high residual retrievals
* Also distinct areas of almost equal probabilities
* Decision Trees
* Rebalance classes
    + Heavy inbalance --> Less model focus on under-populated class
    + Before rebalacing: `r prop.table(table(orig_train$class_resid))` (bad, good)
    + SMOTE (Synthetic Minority Over-Sampling Technique)
    + After rebalancing: `r prop.table(table(orig_train_smote$class_resid))` (bad, good)
    
* Four features:
    + (T_11 - T_12) * Reference SST
        + Measure of atmospheric absorption
    + Horizontalized Temperature Deficit Estimate
        + Temperature deficit estimate: Importance of temperature deficit shown above
        + Horizontalized because decision trees can only draw horizontal/vertical lines
    + sec(satellite zenith angle)
        + Tells how many atmospheres satellite is viewing the ocean through
    + Standard deviation of BTs over a 25 $km^2$ area in the 11 $\mu$m channel
        + Indicates possible cloud contamination
* 3 Decision Tree Algorithms
    + RPart/CART (Recursive Partitioning Trees)
    + CTree (Conditional Inference Trees)
    + Random Forests
* Tuned and pruned models, ensured no overfitting
* Very similar balanced accuracies
* Final choice: CTree
    + Chooses splitting variables through statistical analysis (unlike RPart)
    + Very easy to interpret (unlike Random Forests)
    + Statistics (Test set)
        + Accuracy: 0.7891 $\pm$ 0.0013
        + Balanced Accuracy: 0.7812
        + Sensitivity: 0.7564
        + Specificity: 0.8059

* Analyzed retrievals for which the tree was mispredicting the residual range
    + Mean residual = -0.3346
    + T-test: Disagreements form different population than residuals as a whole (p < 0.05)
    + Mean residual of disagreements = very close to artificial cutoff value of -0.4
    + Mispredictions because residual (continuous) is being discretized into good/bad categories
    
* Decision Tree Regression
    + Instead of predicting a class (i.e., good or bad), tree identifies which node a retrieval
    fits into and then predicts the retrieval's residual as the average residual for all retrievals
    in that node
    
* CTree Regression:
    + Statistics (Test set)
        + RMSE: 0.3940179
        + Correlation between predicted residual and actual residual: 0.7937876
    + However, # of predictions = # of nodes
    + Discrete nature to what should be a continuous prediction
    + Variability in node makes average value a poor prediction of residual

* Cubist/M5P Tree Regression    
    + Instead of predicting the residual as the average value from the train set of residuals in
    a given node, (better way to say this?) Cubist uses a decision tree to determine which
    regression equation should be used on the retrieval to predict its residual
    + Statistics (Test set)
        + RMSE: 0.3612067
        + Average abs(error): 0.256188
        + Correlation between predicted residual and actual residual: 0.831561
    + Can now numerically quantify residual
    + To quantify the certainty of residual estimate, empirical table of test set accuracy windows
        + 14.0% of actual residuals fall within $\pm$ .05 deg C of predicted residual
        + 27.5% of actual residuals fall within $\pm$ .1 deg C of predicted residual
        + 40.2% of actual residuals fall within $\pm$ .15 deg C of predicted residual
        + 51.6% of actual residuals fall within $\pm$ .2 deg C of predicted residual
        + 61.6% of actual residuals fall within $\pm$ .25 deg C of predicted residual
        + 79.1% of actual residuals fall within $\pm$ .375 deg C of predicted residual
        + 88.4% of actual residuals fall within $\pm$ .5 deg C of predicted residual
        + 92.5% of actual residuals fall within $\pm$ .6 deg C of predicted residual
        + 95.0% of actual residuals fall within $\pm$ .7 deg C of predicted residual
        
```{r plot_with_predictions_and_actual, echo=FALSE}

ggplot2::ggplot() +
  geom_point(aes(x = M5P_tree_test_vals, orig_test$SST.resid.SMB), pch = '.') +
  geom_abline(slope = 1, intercept = 0, color = 'tomato') +
  labs(x = 'Predicted Residual from the Cubist Decision Tree Regression Algorithm', y = 'Actual Residual')
```

Caption: Figure 4: Predicted and Actual Residuals from the Cubist Decision Tree Regression Algorithm
        
# Discussion
* Decision Trees = highly interpretable
* Combinations of splitting variables
* Rank variables based on their importance to the model
* Variable importance ranking (according to Cubist tree):
    1. Horizontalized Temperature Deficit Estimate
    2. sec(satellite zenith angle)
    3. (T_11 - T_12) * Reference SST
    4. standard deviation in the 11 $\mu$m channel
* Geophysical insight: In nodes dealing with high SSTs, sec(satz) shows up very regularly
and high up in the tree --> has great importance
* Possible: Deciding whether or not a high SST retrieval will have small or large residual
is largely dependent on how many atmospheres sensor is seeing through (i.e., viewing angle
geometry)

# Conclusion
* Decision Trees with nodes as regression algorithms to numerically quantify the residual
* First-ever numeric quantification of the SST residual
* High accuracy and precision of the residual predictions
* Geophysical insight into what causes some high SST retrievals to have large residuals and
other note to


# Acknowledgements


# References
    

