---
title: "Model-Based Regression from AGU 2017"
author: "Chirag Kumar and Guillermo Podesta"
output:
  html_notebook:
    toc: True
    theme: united
---

In this notebook, we explore the rationale behind the NLSST algorithm and where it fails. We investigate the
correlation between the temperature deficit and band difference. Finally, we aim to use decision trees to
estimate when a retrieval has a low or high residual magnitude based on the above exploration of when the
atmospheric correction is no longer an accurate proxy for the temperature deficit.


# Prep Workspace and Data
We use MODIS matchups from 2002 - 2016 that have been read in through a previous script. Here we simply load
the matchups, any required packages, and define necessary functions.

```{r prep_workspace, include=FALSE}
# Import necessary packages
require(ggplot2)
require(dplyr)
require(RColorBrewer)
require(circular)
require(ggmap)
require(raster)
require(rasterVis)
require(caret)
require(partykit)
require(randomForest)
require(stringr)
require(stringi)
require(raster)
require(sp)
require(rgdal)
require(rasterVis)
require(rpart)
require(rpart.plot)
require(scales)

ggplot <- function(...) {ggplot2::ggplot(...) + theme_bw()}

# Define secant function
secant.deg <- function(x) {1 / (cos(circular::rad(x)))}

# Source own functions
# Define direwctory where functions are for each operating system

if (Sys.info()["sysname"] == 'Windows') {
  fun.dir <- 'D:/matchups/r-projects/Matchup_R_Scripts/Functions/'
} else if (Sys.info()["sysname"] == 'Linux') {
  fun.dir <- '/home/ckk/Projects/Matchup_R_Scripts/Functions/'
}

fun.file <- paste0(fun.dir, 'common_functions.R')

source(file = fun.file,
  local = FALSE, echo = FALSE, verbose = FALSE)
rm(fun.dir, fun.file)


# Load data
# For 787
linux_dir <- '~/Projects/Matchup_R_Scripts/Results/objects/'
# For Laptop
#linux_dir <- '~/Projects/Matchup_R_Scripts/'
linux_file <- 'MODIS_Aqua_GSFC_ALL_Class_6.4.1_ao_2017_04_12_with_ancillary.Rdata'
AQUA_file <- paste0(linux_dir, linux_file)

if (!file.exists(AQUA_file)) {
    stop('Input file does not exist')
  } else {
    load(AQUA_file, verbose = TRUE)
    AQUA <- MODIS_Aqua_GSFC_ALL_Class_6.4.1_ao_2017_04_12
  }

rm(linux_dir, linux_file, AQUA_file)
rm(MODIS_Aqua_GSFC_ALL_Class_6.4.1_ao_2017_04_12)

set.seed(108)
```

The matchup file read in at a previous step is not filtered and contains too many variables. For the purpose of 
this analysis, we use only nighttime matchups with a quality of 0, 1, or 2 and only keep variables from the infrared
channels we use.

```{r prep_data, echo=TRUE}
# Turn POSIXct objects to characters bc dplyr doesn't support POSIXct
AQUA$sat.timedate <- as.character(AQUA$sat.timedate)
AQUA$buoy.timedate <- as.character(AQUA$buoy.timedate)

# Apply basic filtering
AQUA <- dplyr::tbl_df(AQUA) %>%
  dplyr::filter(solz >= 90) %>%
  dplyr::filter(qsst == 0 | qsst == 1 | qsst == 2) # 1130520 Matchups

# Now grab only variables that may be used to determine retrieval accuracy and make some new variables (i.e. x1, x2, x3)
# Create df of features
orig <- dplyr::tbl_df(AQUA) %>%
  dplyr::mutate(T_11 = cen.11000,
    T_12 = cen.12000,
    band.diff = T_11 - T_12,
    ref_SST = cen.ref.type.1.SST,
    x2 = band.diff * ref_SST,
    x3 = ((secant.deg(satz) - 1) * band.diff),
    abs_satz = abs(satz),
    sec_satz = secant.deg(satz),
    lat = buoy.lat,
    lon = buoy.lon,
    month = lubridate::month(as.POSIXct(buoy.timedate)),
    sd11 = sd.11000,
    sd12 = sd.12000,
    range11 = max.11000 - min.11000,
    range12 = max.12000 - min.12000,
    diff.med.min11 = med.11000 - min.11000,
    diff.med.min12 = med.12000 - min.12000,
    qsst = qsst,
    buoy.sst = buoy.sst,
    cell5deg = cell5deg,
    buoy.timedate = buoy.timedate,
    cen.sst = cen.sst,
    pseudo.resid.SMR = cen.sst - cen.ref.type.1.SST,
    td_estimate = ref_SST - T_11,
    SST.resid.SMB = cen.sst - (buoy.sst - 0.17)) %>% # SMB = sat minus buoy - also debias buoy.sst by turning buoy.sst into a skin measurement
  dplyr::select(T_11, T_12, band.diff, ref_SST, x2, x3, satz, abs_satz, sec_satz, lon, lat, sd11, sd12, range11, range12, diff.med.min11,
                diff.med.min12, qsst, buoy.sst, cell5deg, cen.sst, buoy.timedate, pseudo.resid.SMR, td_estimate, SST.resid.SMB)

```

# SST and Residuals

```{r residuals_vs_buoy_SST, echo = TRUE}

cols <- RColorBrewer::brewer.pal(n = 9, 'YlOrRd')
cols <- cols[2:9]

ggplot2::ggplot(data = orig, mapping = aes(x = buoy.sst, y = SST.resid.SMB,
  fill = cut(..count.., c(0, 50, 100, 250, 500, 1000, 2500, 5000, Inf)))) +
  geom_bin2d(bins = 75) +
  scale_fill_manual(values = cols, '# of retrievals') +
  geom_abline(slope = 0, intercept = 0, col = 'black')

```
We see that as the SST increases, so does the spread of the residuals. There are also more retrievals at higher
SSTs. We now explore the NLSST algorithm to find why there is an increase in residual spread at higher SSTs.

After the series of filters that we have applied, we are left with `r nrow(orig)` matchups, ranging from
`r min(orig$buoy.timedate)` to `r max(orig$buoy.timedate)`

# NLSST Exploration
At higher SSTs, the correlation between temperature deficit and band difference (the proxy for temperature deficit)
decreases, as the band difference begins to respond less. This can be seen in the following plot.

```{r band_diff_temp_deficit_qsst_all, echo=TRUE}

ccc <- RColorBrewer::brewer.pal(n = 8, 'YlOrRd')
ccc <- ccc[3:8] 

temp_deficit <- orig$buoy.sst - orig$T_11

# Take a sample of orig bc loess requires lots of memory - for testing purposes
index <- sample(1:nrow(orig), 50000, replace = FALSE)

rrr <- ggplot2::ggplot(mapping = aes(x = orig$band.diff[index], y = temp_deficit[index])) +
  geom_bin2d(bins = 20) +
  scale_fill_gradientn(colours = ccc) +
  geom_smooth(method = lm, se = FALSE, color = 'green', alpha = 0.1) +
  geom_smooth(method = loess, se = FALSE, span = 0.4) +
  labs(x = 'T_11 - T_12', y = 'Temperature Deficit')

rrr
```


The NLSST algorithm corrects for this loss in linearity by not using just the band difference
to predict the temperature deficit but rather a product made up of the band difference times
the reference SST. While better than the trend explored in the previous plot, there is still
a distinct loss of linearity at high SSTs.

```{r product_temp_deficit, echo=TRUE}
# --- These numbers may help perform statistics for the matchups
# --- (e.g., number of matchups per cell, etc.).

temp_deficit_est <- orig$ref_SST - orig$T_11
temp_deficit <- orig$buoy.sst - orig$T_11

uuu <- data.frame(temp_deficit_est = temp_deficit_est, product = (orig$band.diff * orig$ref_SST),
                  temp_deficit = temp_deficit,
                  SST.resid.SMB = orig$SST.resid.SMB)

# Take a sample of uuu bc loess requires lots of memory - for testing purposes
set.seed(108)
#index <- sample(1:nrow(uuu), 100000, replace = FALSE)
#uuu <- uuu[index, ]

# --- Create a raster object with 5-degree pixels

grid5deg <- raster::raster(ncol = 50, nrow = 50,
  xmn = min(uuu$product) - 0.1, xmx = max(uuu$product) + 0.1,
  ymn = min(uuu$temp_deficit) - 0.1, ymx = max(uuu$temp_deficit) + 0.1)
  #crs = crs.string)

# --- Write cell numbers as value for the grids.
# --- Cell 1 is the upper left corner and numbers go
# --- across the top line through its end, then
# --- start again in the second line, and so forth.

raster::values(grid5deg) <- 1:raster::ncell(grid5deg) # Cell numbers for 5 deg grid

raster::cellFromRowCol(object = grid5deg, rownr = 2, colnr = 50)

raster::xyFromCell(object =  grid5deg, cell = 2500, spatial = FALSE)

pts <- data.frame(product = uuu$product, temp_deficit = uuu$temp_deficit)
SST.resid.SMB <- uuu$SST.resid.SMB

count_resids <- function(residuals, ...) {
  return(length(residuals))
}

cell5deg <- raster::rasterize(pts, grid5deg, SST.resid.SMB, fun = count_resids)

ccc <- RColorBrewer::brewer.pal(n = 9, 'YlOrRd')
ccc <- ccc[3:9]
ccc <- colorRampPalette(ccc)(10)

breaks <- c(0, 50/20, 150/20, 250/20, 1000/20, 5000/20, Inf)
breaks <- breaks * 20

# Add loess and linear fits
Xs <- data.frame(Xs = seq(from = 0, to = 140, by = .31115/5.555))

td_lm <- lm(uuu$temp_deficit ~ uuu$product)
lm_estimates <- td_lm$coefficients[1] + (td_lm$coefficients[2] * Xs)
lm_estimates <- as.vector(lm_estimates$Xs)

td_loess <- loess(temp_deficit ~ product, data = uuu, span = 0.4)
loess_estimates <- predict(td_loess, newdata = Xs$Xs)

rasterVis::gplot(cell5deg) + 
  ggplot2::geom_raster(aes(fill = (cut(value, breaks)))) +
  scale_fill_manual(values = ccc) +
  geom_line(aes(x = Xs, y = lm_estimates), color = '#008000') +
  geom_line(aes(x = Xs, y = loess_estimates), color = 'blue') +
  labs(x = 'Scaled Channel Difference (deg C)', y = 'Temperature Deficit (deg C)', fill = '# of Retrievals') +
  coord_fixed(ratio = 2.4) +
  xlim(-2, 122) +
  ylim(-.1, 22) +
  theme_bw() +
  ggsave('x2_vs_TD_loess_and_linear.pdf', device = 'pdf', width = 8, height = 6, units = 'in') +
  ggsave('x2_vs_TD_loess_and_linear.png', device = 'png', width = 8, height = 6, units = 'in')

ggplot2::ggplot() +
  geom_point(pch = '.', data = uuu, aes(product, temp_deficit)) +
  geom_line(aes(x = Xs, y = lm_estimates), color = 'green') +
  geom_line(aes(x = Xs, y = loess_estimates), color = 'blue')
```

```{r loess_minus_linear_residual_effect, echo = TRUE}

linear_predictions <- td_lm$coefficients[1] + td_lm$coefficients[2] * orig$x2
loess_predictions <- predict(td_loess, newdata = orig$x2)

difference <- loess_predictions - linear_predictions

www <- data.frame(difference = difference, resid = orig$SST.resid.SMB)

ccc <- RColorBrewer::brewer.pal(n = 9, 'YlOrRd')
ccc <- ccc[3:9]
breaks <- c(0, 10, 25, 50, 100, 500, 1000, 2500, 5000, 10000, Inf)
ccc <- colorRampPalette(ccc)(length(breaks) - 1)

ggplot2::ggplot(www, aes(x = difference, y = resid, fill = cut(..count.., c(0, 10, 25, 50, 100, 500, 1000, 2500, 5000, 10000, Inf)))) +
  geom_bin2d(bins = 75) +
  scale_fill_manual(values = ccc) +
  labs(x = 'Loess - Linear', y = 'Residual', fill = '# of Retrievals') +
  ggsave('nonlinearity_effect_on_residuals_2d_histogram.pdf', device = 'pdf', width = 8, height = 6, units = 'in')


```



At lower SSTs, there is a strong linear correlation between the product and the temperature deficit,
indicating that at low SSTs, the NLSST atmospheric correction works very well.

We also see that at higher SSTs, there is a breakdown of the linear correlation between the temperature
deficit and product used in the NLSST algorithm (x2). The temperature deficit increases more than
the band difference does, which causes increase in retrievals with negative residuals at higher
temperatures. However, the band difference alone is not enough for us to separate retrievals
with good and bad residual ranges.


```{r binning_retrievals_band_diff_temp_def_residual_a_la_raster_median, echo=TRUE}
# --- These numbers may help perform statistics for the matchups
# --- (e.g., number of matchups per cell, etc.).

temp_deficit_est <- orig$ref_SST - orig$T_11
temp_deficit <- orig$buoy.sst - orig$T_11

uuu <- data.frame(temp_deficit_est = temp_deficit_est, product = (orig$band.diff * orig$ref_SST),
                  temp_deficit = temp_deficit,
                  x3 = orig$x3,
                  sec_satz = secant.deg(orig$satz),
                  SST.resid.SMB = orig$SST.resid.SMB,
                  sec_satz = orig$sec_satz)

# Take a sample of uuu bc loess requires lots of memory - for testing purposes
set.seed(42)
#index <- sample(1:nrow(uuu), 50000, replace = FALSE)
#uuu <- uuu[index, ]

# --- Create a raster object with 5-degree pixels

grid5deg <- raster::raster(ncol = 50, nrow = 50,
  xmn = min(uuu$product) - 0.1, xmx = max(uuu$product) + 0.1,
  ymn = min(uuu$temp_deficit) - 0.1, ymx = max(uuu$temp_deficit) + 0.1)
  #crs = crs.string)

# --- Write cell numbers as value for the grids.
# --- Cell 1 is the upper left corner and numbers go
# --- across the top line through its end, then
# --- start again in the second line, and so forth.

raster::values(grid5deg) <- 1:raster::ncell(grid5deg) # Cell numbers for 5 deg grid

raster::cellFromRowCol(object = grid5deg, rownr = 2, colnr = 50)

raster::xyFromCell(object =  grid5deg, cell = 2500, spatial = FALSE)

pts <- data.frame(product = uuu$product, temp_deficit = uuu$temp_deficit)
SST.resid.SMB <- uuu$SST.resid.SMB
sec_satz <- uuu$sec_satz

cell5deg <- raster::rasterize(pts, grid5deg, SST.resid.SMB, fun = median) # fun can be median, IQR, or count_good_residuals

blues_palette <- rev(RColorBrewer::brewer.pal(9, 'Blues'))
blues_palette <- colorRampPalette(blues_palette)(11)

reds_palette <- RColorBrewer::brewer.pal(9, 'Reds')
reds_palette <- reds_palette[1:4]
reds_palette <- colorRampPalette(reds_palette)(5)

palette_med <- c((blues_palette), (reds_palette))

breaks_med <- c(-Inf, -5, -4.5, -4, -3.5, -3, -2.5, -2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2, Inf)

rasterVis::gplot(cell5deg) + 
  ggplot2::geom_raster(aes(fill = (cut(value, breaks_med)))) +
  scale_fill_manual(values = palette_med) +
  labs(x = 'Scaled Channel Difference (deg C)', y = 'Temperature Deficit (deg C)', fill = 'Median\nResidual (deg C)') +
  coord_fixed(ratio = 2.4) +
  xlim(-2, 122) +
  ylim(-.1, 22) +
  theme(legend.key = element_blank(), legend.key.size = unit(12, "point")) +
  ggsave('x2_vs_TD_raster_median_fine.pdf', device = 'pdf', width = 8, height = 6, units = 'in') +
  ggsave('x2_vs_TD_raster_median_fine.png', device = 'png', width = 8, height = 6, units = 'in')

rasterVis::gplot(cell5deg) + ggplot2::geom_raster(aes(fill = value)) + scale_fill_gradientn(colours = c('blue', 'white', 'red'), breaks = c(-7, 0, 6), labels = format(c('-7', '0', '6'))) + theme_bw() + theme(legend.key = element_blank(), legend.key.size = unit(12, "point"))


blues_palette <- rev(RColorBrewer::brewer.pal(9, 'Blues'))
blues_palette <- blues_palette[1:7]
blues_palette <- colorRampPalette(blues_palette)(4)

reds_palette <- RColorBrewer::brewer.pal(9, 'Reds')
reds_palette <- reds_palette[2:5]
reds_palette <- colorRampPalette(reds_palette)(3)

palette_med <- c((blues_palette), '#ffffff', (reds_palette))

breaks_med <- c(-Inf, -3, -2, -1, -0.2, 0.2, 1, 2, Inf)

Xs <- data.frame(Xs = seq(from = 0, to = 140, by = .31115/5.555))
loess_estimates <- predict(td_loess, newdata = Xs$Xs)

rasterVis::gplot(cell5deg) + 
  ggplot2::geom_raster(aes(fill = (cut(value, breaks_med)))) +
  #geom_line(aes(x = Xs, y = lm_estimates), color = '#008000') +
  #geom_line(aes(x = Xs, y = loess_estimates), color = 'purple') +
  #geom_line(aes(x = Xs, y = loess_estimates + 0.514), color = 'purple') +
  scale_fill_manual(values = palette_med) +
  labs(x = 'Scaled Channel Difference (deg C)', y = 'Temperature Deficit (deg C)', fill = 'Median\nResidual\n(deg C)') +
  coord_fixed(ratio = 2.4) +
  xlim(-2, 122) +
  ylim(-.1, 22) +
  theme(legend.key = element_blank(), legend.key.size = unit(12, "point")) +
  theme_bw() +
  ggsave('x2_vs_TD_raster_median_course.pdf', device = 'pdf', width = 8, height = 6, units = 'in') +
  ggsave('x2_vs_TD_raster_median_course.png', device = 'png', width = 8, height = 6, units = 'in')


```


```{r binning_retrievals_band_diff_temp_def_residual_a_la_raster_IQR, echo=TRUE}
# --- These numbers may help perform statistics for the matchups
# --- (e.g., number of matchups per cell, etc.).

temp_deficit_est <- orig$ref_SST - orig$T_11
temp_deficit <- orig$buoy.sst - orig$T_11

uuu <- data.frame(temp_deficit_est = temp_deficit_est, product = (orig$band.diff * orig$ref_SST),
                  temp_deficit = temp_deficit,
                  x3 = orig$x3,
                  sec_satz = secant.deg(orig$satz),
                  SST.resid.SMB = orig$SST.resid.SMB)

# --- Create a raster object with 5-degree pixels

grid5deg <- raster::raster(ncol = 50, nrow = 50,
  xmn = min(uuu$product) - 0.1, xmx = max(uuu$product) + 0.1,
  ymn = min(uuu$temp_deficit) - 0.1, ymx = max(uuu$temp_deficit) + 0.1)
  #crs = crs.string)

# --- Write cell numbers as value for the grids.
# --- Cell 1 is the upper left corner and numbers go
# --- across the top line through its end, then
# --- start again in the second line, and so forth.

raster::values(grid5deg) <- 1:raster::ncell(grid5deg) # Cell numbers for 5 deg grid

raster::cellFromRowCol(object = grid5deg, rownr = 2, colnr = 50)

raster::xyFromCell(object =  grid5deg, cell = 2500, spatial = FALSE)

pts <- data.frame(product = uuu$product, temp_deficit = uuu$temp_deficit)
SST.resid.SMB <- uuu$SST.resid.SMB

cell5deg <- raster::rasterize(pts, grid5deg, SST.resid.SMB, fun = mad) # fun can be median, IQR, or count_good_residuals

breaks_IQR <- c(seq(from = 0, to = 1.2, by = 0.3), Inf)

palette_IQR <- RColorBrewer::brewer.pal(9, 'Greens')[3:9]
#palette_IQR <- palette_IQR[5:9]
palette_IQR <- colorRampPalette(palette_IQR)(length(breaks_IQR) - 1)

rasterVis::gplot(cell5deg) + 
  ggplot2::geom_raster(aes(fill = (cut(value, breaks_IQR)))) +
  scale_fill_manual(values = palette_IQR) +
  labs(x = 'Scaled Channel Difference (deg C)', y = 'Temperature Deficit (deg C)', fill = 'MAD of\nResiduals\n(deg C)') +
  coord_fixed(ratio = 2.4) +
  xlim(-2, 122) +
  ylim(-.1, 22) +
  theme(legend.key = element_blank(), legend.key.size = unit(12, "point")) +
  theme_bw() +
  ggsave('x2_vs_TD_raster_MAD.pdf', device = 'pdf', width = 8, height = 6, units = 'in') +
  ggsave('x2_vs_TD_raster_MAD.png', device = 'png', width = 8, height = 6, units = 'in')
```


[TEXT TO INSERT]

# Decision Trees

## Prep Data for Decision Trees

### Create Additional Variables

Explored before is that lines can be drawn that are a function of the product and temperature deficit
that segment good and bad retrievals. However, we can't give the temperature deficit (the answer) to
the machine learning model. We create estimates of the temperature deficit using the reference SST
minus T_11 (T_12).

```{r create_additional_variables, echo=TRUE}
# Linearized temperature deficit estimate as a function of NLSST product
orig$td_resid <- orig$td_estimate - predict(td_loess, newdata = orig$x2)

# Month
orig$month <- lubridate::month(as.POSIXct(orig$buoy.timedate))

# Loess can only interpolate
# Those values of x2 that are outside the domain get put in as NA
# Remove those
orig <- dplyr::tbl_df(orig) %>%
  dplyr::filter(!is.na(td_resid))

orig <- as.data.frame(orig)

```

### Split into Train and Test Sets

All our algorithms will be trained on 60% of our data and tested on the other 40%.
We make that split here.

```{r create_train_test_set, echo=TRUE}
# Divide data into training and validation sets
set.seed(108)
prop_train <- .6
len_train <- floor(prop_train * nrow(orig))
index <- sample(1:nrow(orig), len_train, replace = FALSE)

orig_train <- orig[index, ]
orig_test <- orig[-index, ]
```


## Regression Trees

```{r ctree_big_4_variable_tree_regr, echo=TRUE}

# Build the tree
ctree_big_4_var_tree_regr <- partykit::ctree(formula = SST.resid.SMB ~ td_resid + x2 + satz + sd11 + lat + month + ref_SST,
                                 data = orig_train,
                                 minbucket = 82,
                                 maxdepth = 7,
                                 mincrit = 0.95)
# Plot the tree
#plot(partykit::as.party(rpart_big_4_var_tree_regr))

# Evaluate the tree
## Use the tree to predict
### Train set
ctree_big_4_var_tree_train_vals <- stats::predict(object = ctree_big_4_var_tree_regr, newdata = orig_train, na.action = na.pass)

### Test set
ctree_big_4_var_tree_test_vals <- stats::predict(object = ctree_big_4_var_tree_regr, newdata = orig_test, na.action = na.pass)

### Train set
rmse_train_ctree <- caret::RMSE(ctree_big_4_var_tree_train_vals, orig_train$SST.resid.SMB)
rmse_train_ctree
cor(ctree_big_4_var_tree_train_vals, orig_train$SST.resid.SMB)

### Test set
rmse_test_ctree <- caret::RMSE(ctree_big_4_var_tree_test_vals, orig_test$SST.resid.SMB)
rmse_test_ctree
cor(ctree_big_4_var_tree_test_vals, orig_test$SST.resid.SMB)

ggplot2::ggplot() +
  geom_point(aes(x = ((ctree_big_4_var_tree_test_vals)), orig_test$SST.resid.SMB), pch = '.')

fit_ctree_lm <- lm(orig_test$SST.resid.SMB ~ ctree_big_4_var_tree_test_vals)
```

```{r evaluate_ctree_regression_statistically, echo=TRUE}

window <- .1

dt_model_residuals_train <- ctree_big_4_var_tree_train_vals - orig_train$SST.resid.SMB

table(abs(dt_model_residuals_train) < window)
prop.table(table(abs(dt_model_residuals_train) < window))
IQR(dt_model_residuals_train)


dt_model_residuals_test <- ctree_big_4_var_tree_test_vals - orig_test$SST.resid.SMB

table(abs(dt_model_residuals_test) < window)
prop.table(table(abs(dt_model_residuals_test) < window))
IQR(dt_model_residuals_test)


```

```{r explore_regression_ctree}
ctree_big_4_var_tree_train_nodes <- stats::predict(object = ctree_big_4_var_tree_regr, newdata = orig_train, type = 'node', na.action = na.pass)

medians_ctree <- tapply(orig_train$SST.resid.SMB, ctree_big_4_var_tree_train_nodes, median)
IQRs_ctree <- tapply(orig_train$SST.resid.SMB, ctree_big_4_var_tree_train_nodes, IQR)
lengths_ctree <- tapply(orig_train$SST.resid.SMB, ctree_big_4_var_tree_train_nodes, length)

node_predictions_ctree <- data.frame(SST.resid.SMB = orig_train$SST.resid.SMB, node = ctree_big_4_var_tree_train_nodes)

ggplot2::ggplot(data = node_predictions_ctree) +
  geom_histogram(aes(SST.resid.SMB)) +
  facet_wrap(~node)

```


## Cubist Regression Models

```{r Cubist, echo=TRUE}
Cubist_rules <- Cubist::cubist(x = orig_train[, c('td_resid', 'x2', 'satz', 'ref_SST', 'lat', 'month', 'sd11')], y = orig_train$SST.resid.SMB,
                              committees = 1,
                              # Full data set: __ rules (no lat or month), 55 rules (both lat and month) 
                              control = Cubist::cubistControl(rules = 28,
                                                              unbiased = FALSE,
                                                              extrapolation = 100,
                                                              label = 'SST Residual',
                                                              seed = 108))

capture.output(summary(Cubist_rules), file = 'Cubist_rules=28_committees=1_with_lat_and_month_Mar16.2017.txt')

dotplot(Cubist_rules, what = 'splits')
dotplot(Cubist_rules, what = 'coefs')

# Evaluate the tree
## Use the tree to predict
### Train set
N_correction_neighbors <- 8 # Must be between 0 and 9

Cubist_rules_train_vals <- stats::predict(object = Cubist_rules, newdata = orig_train, na.action = na.pass, neighbors = N_correction_neighbors)

### Test set
Cubist_rules_test_vals <- stats::predict(object = Cubist_rules, newdata = orig_test, na.action = na.pass, neighbors = N_correction_neighbors)


### Train set
RMSE_train_cubist <- caret::RMSE(Cubist_rules_train_vals, orig_train$SST.resid.SMB)
RMSE_train_cubist
MAE_train_cubist <- mean(abs(Cubist_rules_train_vals - orig_train$SST.resid.SMB))
MAE_train_cubist
IQR(Cubist_rules_train_vals - orig_train$SST.resid.SMB)
median(Cubist_rules_train_vals - orig_train$SST.resid.SMB)
cor(Cubist_rules_train_vals, orig_train$SST.resid.SMB)

### Test set
RMSE_test_cubist <- caret::RMSE(Cubist_rules_test_vals, orig_test$SST.resid.SMB)
RMSE_test_cubist
MAE_test_cubist <- mean(abs(Cubist_rules_test_vals - orig_test$SST.resid.SMB))
MAE_test_cubist
IQR(Cubist_rules_test_vals - orig_test$SST.resid.SMB)
median(Cubist_rules_test_vals - orig_test$SST.resid.SMB)
cor(Cubist_rules_test_vals, orig_test$SST.resid.SMB)

ggplot2::ggplot() +
  geom_point(aes(x = Cubist_rules_test_vals, orig_test$SST.resid.SMB), pch = '.') +
  geom_abline(slope = 1, intercept = 0, color = 'tomato') +
  labs(x = 'Predicted Residual from the Cubist Decision Tree Regression Algorithm', y = 'Actual Residual')
  #ggsave('M5P_predictions_vs_actual_residual.svg', device = 'svg', width = 8, height = 6, units = 'in')

ccc <- RColorBrewer::brewer.pal(n = 9, 'YlOrRd')
ccc <- ccc[3:9]
breaks <- c(0, 10, 25, 50, 100, 500, 1000, 2500, 5000, 10000, Inf)

yyy <- data.frame(Y = Cubist_rules_test_vals, X = orig_test$SST.resid.SMB)

ccc <- colorRampPalette(ccc)(length(breaks) - 1)

ggplot2::ggplot(data = yyy, aes(X, Y, fill = cut(..count.., c(0, 10, 25, 50, 100, 500, 1000, 2500, 5000, 10000, Inf)))) +
  geom_bin2d(bins = 75) +
  scale_fill_manual(values = ccc, '# of Retrievals') +
  geom_abline(slope = 1, intercept = 0, color = 'black') +
  labs(x = 'Actual Residual (deg C)', y = 'Predicted Residual (deg C)')
  #ggsave('Cubist_predictions_vs_actual_residual_2d_histogram.pdf', device = 'pdf', width = 8, height = 6, units = 'in') + 
  #ggsave('Cubist_predictions_vs_actual_residual_2d_histogram.png', device = 'png', width = 8, height = 6, units = 'in')

residual_fit_cubist <- lm(Y ~ X, data = yyy)
residual_fit_cubist

```
```{r grid_search_for_committees_and_rules, echo = TRUE}
set.seed(108)
too_small <- FALSE
committees <- seq(from = 1, to = 1)
rules <- seq(from = 1, to = 100)
ctrl_params_performance <- expand.grid(rules = rules, committees = committees)
ctrl_params_performance$RMSE_train <- rep(NA, nrow(ctrl_params_performance))
ctrl_params_performance$RMSE_test <- rep(NA, nrow(ctrl_params_performance))

for (N in 1:nrow(ctrl_params_performance)) {
  committees_specific <- ctrl_params_performance[N, 'committees']
  rules_specific <- ctrl_params_performance[N, 'rules']
  
  if (rules_specific == 1) {
    too_small <- FALSE
  }
  
  if (!too_small) {
   
    Cubist_rules <- Cubist::cubist(x = orig_train[, c('lat', 'month', 'sd11', 'td_resid', 'x2', 'satz', 'ref_SST')], y = orig_train$SST.resid.SMB,
                           committees = committees_specific, 
                           control = Cubist::cubistControl(rules = rules_specific,
                                                           unbiased = FALSE,
                                                           extrapolation = 100,
                                                           label = 'SST Residual',
                                                           seed = 108))
  
    file <- paste0('Cubist_Rule_Sets/Cubist_rules=', rules_specific, '_committees=', committees_specific, '_with_lat_and_month.txt')
    capture.output(summary(Cubist_rules), file = file)
  
    rule_summary <- summary(Cubist_rules)
  
    node_sizes <- rep(NA, rules_specific)
    node_sizes <- as.data.frame(node_sizes)
    mmm <- strsplit(paste(rule_summary), '\n')
    mmm <- as.vector(unlist(mmm))
    counter <- 0
    for (K in 1:length(mmm)) {
      line_specific <- mmm[K]
    
      if (substring(line_specific, 1, 7) == "  Rule ") {
        cases_in_node <- stringr::str_extract(line_specific, '[0-9]+ cases')
        cases_in_node <- substring(cases_in_node, 1, stringi::stri_length(cases_in_node) - 6)
        cases_in_node <- as.numeric(cases_in_node)
      
        node_sizes[counter + 1] <- cases_in_node
        counter <- counter + 1
      }
    
    }
  
    if (min(node_sizes) >= 100) {
      # Compute the RMSE on a random sample of data 
    
      N_correction_neighbors <- 9 # Must be between 0 and 9
    
      uuu <- orig_train
      index <- sample(1:nrow(uuu), 100000, replace = FALSE)
      uuu <- uuu[index, ]
    
      zzz <- orig_test
      index <- sample(1:nrow(zzz), 100000, replace = FALSE)
      zzz <- zzz[index, ]
    
      ### Train set
      Cubist_rules_train_vals <- stats::predict(object = Cubist_rules, newdata = uuu, na.action = na.pass, neighbors = N_correction_neighbors)

      ### Test set
      Cubist_rules_test_vals <- stats::predict(object = Cubist_rules, newdata = zzz, na.action = na.pass, neighbors = N_correction_neighbors)

      ### Train set
      RMSE_train_cubist <- caret::RMSE(Cubist_rules_train_vals, uuu$SST.resid.SMB)
      ctrl_params_performance[N, 'RMSE_train'] <- RMSE_train_cubist

      ### Test set
      RMSE_test_cubist <- caret::RMSE(Cubist_rules_test_vals, zzz$SST.resid.SMB)
      ctrl_params_performance[N, 'RMSE_test'] <- RMSE_test_cubist
    
      too_small <- FALSE
    
      cat('Committees:', committees_specific, 'out of 1; Rules:', rules_specific, 'out of 100; RMSE Test:', RMSE_test_cubist, '\n')
      
      rm(Cubist_rules)
      gc()
      
    } else {
    
      too_small <- FALSE
    } 
    
  }
  
}

```

### Exploring and Evaluating the Cubist Regression
```{r evaluate_Cubist_regression_statistically, echo=TRUE}

window <- .4

Cubist_rules_residuals_train <- Cubist_rules_train_vals - orig_train$SST.resid.SMB

table(abs(Cubist_rules_residuals_train) < window)
prop.table(table(abs(Cubist_rules_residuals_train) <= window))
IQR(Cubist_rules_residuals_train)


Cubist_rules_residuals_test <- Cubist_rules_test_vals - orig_test$SST.resid.SMB

table(abs(Cubist_rules_residuals_test) < window)
prop.table(table(abs(Cubist_rules_residuals_test) <= window))
IQR(Cubist_rules_residuals_test)

```

```{r evaluate_Cubist_regression_statistically_plot, echo=TRUE}
windows <- seq(from = 0, to = 1.0, by = .01)

prob_in_window <- windows

for (i in seq(1, length(windows))) {
  Cubist_rules_residuals_test <- Cubist_rules_test_vals - orig_test$SST.resid.SMB

  window <- windows[i]
  ooo <- prop.table(table(abs(Cubist_rules_residuals_test) < window))
  prob_in_window[i] <- ooo[2]
}

prob_in_window <- prob_in_window * 100

ggplot2::ggplot() +
  geom_point(aes(x = windows, y = prob_in_window)) +
  xlim(0, 1.0) +
  ylim(0, 100) +
  labs(x = 'Plus/Minus Interval', y = '% Retrievals with abs(Predicted - Actual Residual) < Interval')
  #ggsave('M5P_predictions_within_interval.svg', device = 'svg', width = 8, height = 6, units = 'in')

```


```{r rule_distribution_Cubist, echo=TRUE}
# Join train and test for rule assignments
orig_b <- rbind(orig_train, orig_test)

# Create empty columns for rule assignments
orig_b$rule_numb <- rep(NA, nrow(orig_b))

# Rule 1
orig_b$rule_numb[orig_b$td_resid > 0.5102545 & orig_b$satz > -0.2305 & orig_b$satz <= 48.5194 & orig_b$ref_SST > 24.6] <- 1

# Rule 2
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid > 0.5102545 & orig_b$satz > -45.4611 & orig_b$satz <= -0.2305] <- 2

# Rule 3
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid > 0.5102545 & orig_b$satz > -0.2305 & orig_b$satz <= 48.5194 & orig_b$ref_SST <= 24.6] <- 3

# Rule 4
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid > 0.5102545 & orig_b$x2 <= 45.74037 & orig_b$satz > 48.5194 & orig_b$ref_SST <= 24.93 & orig_b$lat <= 23.03] <- 4

# Rule 5
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid > 0.5102545 & orig_b$x2 <= 21.57097 & orig_b$satz > 48.5194 & orig_b$lat > 23.03] <- 5

# Rule 6
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$x2 > 56.21659 & orig_b$satz > -37.75 & orig_b$satz <= 2.561 & orig_b$ref_SST > 24.57] <- 6

# Rule 7
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$x2 <= 49.05643 & orig_b$satz <= -45.4611 & orig_b$ref_SST > 25.2 & orig_b$lat <= 25.99] <- 7

# Rule 8
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$x2 <= 45.74037 & orig_b$satz > 48.5194 & orig_b$ref_SST > 24.93 & orig_b$lat <= 23.03] <- 8

# Rule 9
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$x2 > 57.63554 & orig_b$satz > 2.561 & orig_b$satz <= 40.15 & orig_b$ref_SST > 24.065] <- 9

# Rule 10
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid > 0.5102545 & orig_b$x2 <= 18.49491 & orig_b$satz <= -45.4611 & orig_b$lat > 25.99] <- 10

# Rule 11
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$x2 > 45.74037 & orig_b$satz > 48.5194] <- 11

# Rule 12
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$x2 > 49.05643 & orig_b$satz <= -45.4611] <- 12

# Rule 13
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$x2 > 21.57097 & orig_b$satz > 48.5194 & orig_b$lat > 23.03] <- 13

# Rule 14
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$x2 > 18.49491 & orig_b$satz <= -45.4611 & orig_b$lat > 25.99] <- 14

# Rule 15
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$x2 <= 49.05643 & orig_b$satz <= -45.4611 & orig_b$ref_SST <= 25.2 & orig_b$lat <= 25.99] <- 15

# Rule 16
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5102545 & orig_b$x2 <= 56.21659 & orig_b$satz > -37.75 & orig_b$satz <= 2.561 & orig_b$ref_SST > 24.57] <- 16

# Rule 17
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5102545 & orig_b$x2 <= 57.63554 & orig_b$satz > 2.561 & orig_b$satz <= 40.15 & orig_b$ref_SST > 24.065] <- 17

# Rule 18
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5102545 & orig_b$x2 <= 58.59198 & orig_b$satz > 40.15 & orig_b$ref_SST > 24.065 & orig_b$lat <= 23.35] <- 18

# Rule 19
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5102545 & orig_b$satz <= 2.561 & orig_b$ref_SST <= 24.57 & orig_b$lat <= -18.35] <- 19

# Rule 20
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5102545 & orig_b$x2 <= 55.50642 & orig_b$satz <= -37.75 & orig_b$ref_SST > 24.57] <- 20

# Rule 21
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5102545 & orig_b$satz > 2.561 & orig_b$satz <= 44.3389 & orig_b$ref_SST <= 24.065] <- 21

# Rule 22
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5102545 & orig_b$x2 > 58.59198 & orig_b$satz > 40.15] <- 22

# Rule 23
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5102545 & orig_b$x2 > 55.50642 & orig_b$satz <= -37.75] <- 23

# Rule 24
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5102545 & orig_b$satz > -45.3389 & orig_b$satz <= 2.561 & orig_b$ref_SST <= 24.57 & orig_b$lat > -18.35] <- 24

# Rule 25
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5102545 & orig_b$x2 <= 58.59198 & orig_b$satz > 40.15 & orig_b$ref_SST > 24.065 & orig_b$lat > 23.35] <- 25

# Rule 26
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5102545 & orig_b$satz > 44.3389 & orig_b$ref_SST <= 24.065 & orig_b$lat <= 32.84] <- 26

# Rule 27
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5102545 & orig_b$satz > 44.3389 & orig_b$ref_SST <= 24.065 & orig_b$lat > 32.84] <- 27

# Rule 28
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5102545 & orig_b$satz <= -45.3389 & orig_b$ref_SST <= 24.57 & orig_b$lat > -18.35] <- 28

# Break back into train and test again
orig_train <- orig_b[1:nrow(orig_train), ]
orig_test <- orig_b[(nrow(orig_train) + 1):nrow(orig_b), ]

```

```{r rule_distribution_Cubist_mar8, echo=TRUE}
# Join train and test for rule assignments
orig_b <- rbind(orig_train, orig_test)

# Create empty columns for rule assignments
orig_b$rule_numb <- rep(NA, nrow(orig_b))

# Rule 1
orig_b$rule_numb[orig_b$td_resid > 0.5120884 & orig_b$satz > -45.5 & orig_b$satz <= 0.1999] <- 1

# Rule 2
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid > 0.5120884 & orig_b$satz > 0.1999 & orig_b$satz <= 49.2] <- 2

# Rule 3
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid > 0.5120884 & orig_b$satz > 49.2 & orig_b$lat <= -2.11 & orig_b$sd11 > 0.2059] <- 3

# Rule 4
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid > 0.5120884 & orig_b$x2 <= 22.06817 & orig_b$satz <= 0.1999 & orig_b$lat <= 25.37] <- 4

# Rule 5
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid > 0.5120884 & orig_b$x2 <= 14.29007 & orig_b$satz > 49.2 & orig_b$lat <= 23.03] <- 5

# Rule 6
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$x2 > 56.11533 & orig_b$satz > -37.4888 & orig_b$satz <= 1.8305] <- 6

# Rule 7
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$x2 <= 64.16445 & orig_b$satz > 49.2 & orig_b$lat > -2.11 & orig_b$lat <= 23.03] <- 7

# Rule 8
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$x2 > 64.16445 & orig_b$satz > 49.2] <- 8

# Rule 9
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$x2 > 57.63554 & orig_b$satz > 1.8305 & orig_b$satz <= 40.15 & orig_b$ref_SST > 25.345] <- 9

# Rule 10
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid > 0.5120884 & orig_b$x2 <= 18.5143 & orig_b$satz <= -45.5 & orig_b$lat > 25.37] <- 10

# Rule 11
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$x2 > 22.06817 & orig_b$satz <= -45.5 & orig_b$ref_SST > 28.885] <- 11

# Rule 12
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$x2 > 61.07097 & orig_b$satz > 40.15] <- 12

# Rule 13
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$x2 > 22.06817 & orig_b$satz <= -45.5 & orig_b$ref_SST <= 28.885 & orig_b$lat <= 25.37] <- 13

# Rule 14
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$x2 > 24.93083 & orig_b$satz > 49.2 & orig_b$lat > 23.03] <- 14

# Rule 15
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$x2 > 18.5143 & orig_b$satz <= -45.5& orig_b$lat > 25.37] <- 15

# Rule 16
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$x2 > 14.29007 & orig_b$satz > 49.2 & orig_b$lat <= -2.11 & orig_b$sd11 <= 0.2059] <- 16

# Rule 17
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$x2 <= 24.93083 & orig_b$satz > 49.2 & orig_b$lat > 23.03] <- 17

# Rule 18
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5120884 & orig_b$x2 <= 56.11533 & orig_b$satz > -37.4888 & orig_b$satz <= 1.8305 & orig_b$ref_SST > 24.855] <- 18

# Rule 19
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5120884 & orig_b$x2 <= 57.63554 & orig_b$satz > 1.8305 & orig_b$satz <= 40.15 & orig_b$ref_SST > 25.345] <- 119

# Rule 20
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5120884 & orig_b$x2 <= 61.07097 & orig_b$satz > 40.15 & orig_b$ref_SST > 25.345 & orig_b$lat <= 20.27] <- 20

# Rule 21
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5120884 & orig_b$satz <= 1.8305  & orig_b$ref_SST <= 24.855 & orig_b$lat <= -18.61] <- 21

# Rule 22
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5120884 & orig_b$satz > 1.8305 & orig_b$satz <= 44.0305 & orig_b$ref_SST <= 25.345] <- 22

# Rule 23
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5120884 & orig_b$x2 <= 53.19009 & orig_b$satz <= -37.4888 & orig_b$ref_SST > 24.855] <- 23

# Rule 24
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5120884 & orig_b$x2 > 53.19009 & orig_b$satz <= -37.4888] <- 24

# Rule 25
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5120884 & orig_b$satz > -50.0305 & orig_b$satz <= 1.8305 & orig_b$ref_SST <= 24.855 & orig_b$lat > -18.61] <- 25

# Rule 26
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5120884 & orig_b$satz > 40.15 & orig_b$ref_SST > 25.345 & orig_b$lat > 20.27] <- 26

# Rule 27
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5120884 & orig_b$satz > 44.0305 & orig_b$ref_SST <= 25.345] <- 27

# Rule 28
orig_b$rule_numb[is.na(orig_b$rule_numb) & orig_b$td_resid <= 0.5120884 & orig_b$satz <= -50.0305 & orig_b$ref_SST <= 24.855 & orig_b$lat > -18.61] <- 28

# Break back into train and test again
orig_train <- orig_b[1:nrow(orig_train), ]
orig_test <- orig_b[(nrow(orig_train) + 1):nrow(orig_b), ]

```

```{r rule_set_9_and_22_hists, echo=TRUE}

ggplot2::ggplot() +
  geom_histogram(data = orig_train[orig_train$rule_numb == 9, ], aes(SST.resid.SMB), bins = 100, col = 'tomato') +
  geom_vline(xintercept = mean(orig_train[orig_train$rule_numb == 9, "SST.resid.SMB"])) +
  geom_histogram(data = orig_train[orig_train$rule_numb == 22, ], aes(SST.resid.SMB), bins = 100, col = 'blue') +
  geom_vline(xintercept = mean(orig_train[orig_train$rule_numb == 22, "SST.resid.SMB"])) +
  labs(x = 'Actual Residual  (deg C)', y = '# of Retrievals')
  #xlim(-3.5, 3.5)


mmm <- dplyr::tbl_df(orig_test) %>%
  dplyr::filter(rule_numb == 8)

nnn <- dplyr::tbl_df(orig_test) %>%
  dplyr::filter(rule_numb == 24)

eee <- rbind(mmm, nnn)

ggplot2::ggplot() + 
  geom_histogram(data = mmm, aes(x = SST.resid.SMB), col = '#084A92', fill = '#084A92', alpha = 0.3, bins = 100) +
  geom_histogram(data = nnn, aes(SST.resid.SMB), col = '#72af2f', fill = '#72af2f', alpha = 0.3, bins = 100) +
  geom_segment(aes(x = median(mmm$SST.resid.SMB), xend = median(mmm$SST.resid.SMB), y = 0, yend = Inf), col = 'black') +
  geom_segment(aes(x = median(nnn$SST.resid.SMB), xend = median(nnn$SST.resid.SMB), y = 0, yend = Inf), col = 'black') +
  annotate('text', x = -3, y = 100, label = 'Rule Set 8 (Blue):\nMedian Residual = -0.38 deg C*', size = 4.) +
  annotate('text', x = 2.1, y = 100, label = 'Rule Set 24 (Green):\nMedian Residual = -0.145 deg C*', size = 4.) +
  annotate('text', x = -.5, y = -8.5, label = '*The populations of the two rule sets were found to be statistically different with t = 13.74 and p < 0.0001.', size = 3) +
  labs(x = 'Actual Residual  (deg C)', y = '# of Retrievals') +
  ggsave('rule_set_8_and_24.png', device = 'png', width = 8, height = 6, units = 'in')

ggplot2::ggplot() +
  geom_point(data = mmm, aes(x = x2, y = td_resid + predict(td_loess, newdata = mmm$x2)), col = '#084A92', alpha = 0.3) +
  geom_point(data = nnn, aes(x = x2, y = td_resid + predict(td_loess, newdata = nnn$x2)), col = '#72af2f', alpha = 0.3) +
  labs(x = 'Scaled Channel Difference (deg C)', y = 'Temperature Deficit (deg C)') +
  xlim(-2, 122) +
  ylim(-.1, 22) +
  annotate('text', x = 60, y = 17.5, label = 'Rule Set 8: Blue', size = 4) +
  annotate('text', x = 60, y = 5, label = 'Rule Set 24: Green', size = 4) +
  ggsave('rule_set_8_and_24_x2_tde.png', device = 'png', width = 8, height = 6, units = 'in')
```


```{r spatial_distribution, echo=TRUE}
mp <- NULL
mapWorld <- borders("world", colour = "gray50", fill = "gray70") # create a layer of borders
mp <- ggplot() +  mapWorld +
  ggplot2::scale_x_continuous(breaks = seq(from = -180, to = 180, by = 60)) +
  ggplot2::scale_y_continuous(breaks = seq(from = -90, to = 90, by = 30)) +
  coord_fixed(ratio = 1)

# WARNING: Be careful as this worked with ggplot2 2.1.0 on Linux
# Try to work on different machines with varying versions of ggplot2
# Now layer the buoys on top with hexagonal binning
mp <- mp + 
  ggplot2::stat_binhex(data = eee,
    aes(x = lon, # Use hexagonal binning command and give x and y input
    y = lat,
    fill = cut(..count.., c(0, 50, 100, 250, 500, 1000, Inf))), # Divides matchups per bin into discrete chunks and colors likewise
    binwidth = c(10, 10)) +
  mapWorld + labs(x = NULL, y = NULL) +
  #scale_fill_hue('value') + # Standard colors with discrete chunking
  scale_fill_brewer(palette = 'YlOrRd') + # Change colors to Yellow, Orange, and Red - many diff 
  guides(fill = guide_legend(title = "N of matchups"))

#ggplot2::ggsave(filename = 'spatial_distribution.ps', device = 'ps',
#       width = 8, height = 6, units = 'in')

mp
```




```{r tree_reconstruction_of_rules, echo=TRUE}

tree_recon <- rpart::rpart(formula = rule_numb ~ td_resid + lat + month + satz + x2 + ref_SST + sd11,
                           data = orig_train,
                           control = rpart::rpart.control(minbucket = 1, maxdepth = 11, cp = 0.0))

plot(tree_recon)
rpart.plot::prp(tree_recon, uniform = TRUE, main = 'Rule Sets')
plot(partykit::as.party(tree_recon))

tree_predics_train <- stats::predict(tree_recon, newdata = orig_train, na.action = na.pass)
tree_predics_train_cm <- caret::confusionMatrix(data = tree_predics_train, reference = orig_train$rule_numb)
tree_predics_train_cm

tree_predics_test <- stats::predict(tree_recon, newdata = orig_test, na.action = na.pass)
tree_predics_test_cm <- caret::confusionMatrix(data = tree_predics_test, reference = orig_test$rule_numb)
tree_predics_test_cm

```


```{r explore_partition_statistics, echo = TRUE}

orig_train$error <- orig_train$SST.resid.SMB - Cubist_rules_train_vals
orig_test$error <- orig_test$SST.resid.SMB - Cubist_rules_test_vals

orig_train$squared_error <- (orig_train$error) ^ 2
orig_test$squared_error <- (orig_test$error) ^ 2

medians_train <- tapply(orig_train$SST.resid.SMB, orig_train$rule_numb, median)
IQRs_train <- tapply(orig_train$SST.resid.SMB, orig_train$rule_numb, IQR)
lengths_train <- tapply(orig_train$SST.resid.SMB, orig_train$rule_numb, length)

mean_sqr_error_train <- tapply(orig_train$squared_error, orig_train$rule_numb, mean)
RMSE_partition_train <- (mean_sqr_error_train) ^ 0.5

medians_test <- tapply(orig_test$SST.resid.SMB, orig_test$rule_numb, median)
IQRs_test <- tapply(orig_test$SST.resid.SMB, orig_test$rule_numb, IQR)
lengths_test <- tapply(orig_test$SST.resid.SMB, orig_test$rule_numb, length)

mean_sqr_error_test <- tapply(orig_test$squared_error, orig_test$rule_numb, mean)
RMSE_partition_test <- (mean_sqr_error_test) ^ 0.5

```


#
```{r schematic_diagram_lowest_resid_magnitude, echo = TRUE}

ggplot2::ggplot() +
  geom_histogram(bins = 50, aes(orig_train$SST.resid.SMB[orig_train$rule_numb == 21])) +
  labs(x = 'Actual Residual  (deg C)', y = '# of Retrievals') +
  xlim(-4, 2) +
  ylim(0, 15000) +
  annotate('text', x = -2.5, y = 13500, label = 'Size: 87113 Retrievals', size = 8) +
  annotate('text', x = -2.5, y = 12500, label = 'Median: -0.0100 deg C', size = 8) +
  annotate('text', x = -2.5, y = 11500, label = 'IQR: 0.46 deg C', size = 8) +
  annotate('text', x = -2.5, y = 10500, label = 'Uncertainty: 0.314 deg C', size = 8) +
  ggsave('lowest_resid_magnitude_partition_histogram.pdf', device = 'pdf', width = 8, height = 6, units = 'in') +
  ggsave('lowest_resid_magnitude_partition_histogram.png', device = 'png', width = 8, height = 6, units = 'in')

ccc <- RColorBrewer::brewer.pal(n = 9, 'YlOrRd')
ccc <- ccc[3:9]
breaks <- c(0, 10, 25, 50, 100, 500, 1000, 2500, Inf)
ccc <- colorRampPalette(ccc)(length(breaks) - 1)

rrr <- data.frame(X = orig_train$SST.resid.SMB[orig_train$rule_numb == 21], Y = Cubist_rules_train_vals[orig_train$rule_numb == 21])

ggplot2::ggplot(data = rrr, aes(x = X, y = Y, fill = cut(..count.., c(0, 10, 25, 50, 100, 500, 1000, 2500, Inf)))) +
  geom_bin2d(bins = 75) +
  geom_abline(slope = 1, intercept = 0, col = 'black') +
  scale_fill_manual(values = ccc) + 
  labs(x = 'Actual Residual (deg C)', y = 'Predicted Residual (deg C)', fill = '# of Retrievals') +
  ggsave('lowest_resid_magnitude_partition_predictions_vs_actual.pdf', device = 'pdf', width = 8, height = 6, units = 'in')

```

```{r schematic_diagram_highest_resid_magnitude, echo = TRUE}

ggplot2::ggplot() +
  geom_histogram(bins = 50, aes(orig_train$SST.resid.SMB[orig_train$rule_numb == 1])) +
  labs(x = 'Actual Residual (deg C)', y = '# of Retrievals') +
  xlim(-4, 2) +
  ylim(0, 400) +
  annotate('text', x = .67, y = 380, label = 'Size: 4968 Retrievals', size = 8) +
  annotate('text', x = .67, y = 355, label = 'Median: -1.89 deg C', size = 8) +
  annotate('text', x = .67, y = 330, label = 'IQR: 1.1 deg C', size = 8) +
  annotate('text', x = .67, y = 305, label = 'Uncertainty: 0.376 deg C', size = 8) +
  ggsave('highest_resid_magnitude_partition_histogram.pdf', device = 'pdf', width = 8, height = 6, units = 'in') +
  ggsave('highest_resid_magnitude_partition_histogram.png', device = 'png', width = 8, height = 6, units = 'in')

ccc <- RColorBrewer::brewer.pal(n = 9, 'YlOrRd')
ccc <- ccc[3:9]
breaks <- c(0, 10, 25, 50, 100, 500, 1000, 2500, Inf)
ccc <- colorRampPalette(ccc)(length(breaks) - 1)

rrr <- data.frame(X = orig_train$SST.resid.SMB[orig_train$rule_numb == 1], Y = Cubist_rules_train_vals[orig_train$rule_numb == 1])

ggplot2::ggplot(data = rrr, aes(x = X, y = Y, fill = cut(..count.., c(0, 10, 25, 50, 100, 500, 1000, 2500, Inf)))) +
  geom_bin2d(bins = 75) +
  geom_abline(slope = 1, intercept = 0, col = 'black') +
  scale_fill_manual(values = ccc) + 
  labs(x = 'Actual Residual (deg C)', y = 'Predicted Residual (deg C)', fill = '# of Retrievals') +
  ggsave('highest_resid_magnitude_partition_predictions_vs_actual.pdf', device = 'pdf', width = 8, height = 6, units = 'in')

```

```{r schematic_diagram_lowest_uncertainty, echo = TRUE}

ggplot2::ggplot() +
  geom_histogram(bins = 50, aes(orig_train$SST.resid.SMB[orig_train$rule_numb == 19])) +
  labs(x = 'Actual Residual (deg C)', y = '# of Retrievals') +
  xlim(-4, 2) +
  ylim(0, 7500) +
  annotate('text', x = -2.5, y = 7000, label = 'Size: 39791 Retrievals', size = 8) +
  annotate('text', x = -2.5, y = 6550, label = 'Median: -0.0338 deg C', size = 8) +
  annotate('text', x = -2.5, y = 6100, label = 'IQR: 0.252 deg C', size = 8) +
  annotate('text', x = -2.5, y = 5650, label = 'Uncertainty: 0.255 deg C', size = 8) +
  ggsave('lowest_uncertainty_partition_histogram.pdf', device = 'pdf', width = 8, height = 6, units = 'in') +
  ggsave('lowest_uncertainty_partition_histogram.png', device = 'png', width = 8, height = 6, units = 'in')

ccc <- RColorBrewer::brewer.pal(n = 9, 'YlOrRd')
ccc <- ccc[3:9]
breaks <- c(0, 10, 25, 50, 100, 500, 1000, 2500, Inf)
ccc <- colorRampPalette(ccc)(length(breaks) - 1)

rrr <- data.frame(X = orig_train$SST.resid.SMB[orig_train$rule_numb == 19], Y = Cubist_rules_train_vals[orig_train$rule_numb == 19])

ggplot2::ggplot(data = rrr, aes(x = X, y = Y, fill = cut(..count.., c(0, 10, 25, 50, 100, 500, 1000, 2500, Inf)))) +
  geom_bin2d(bins = 75) +
  geom_abline(slope = 1, intercept = 0, col = 'black') +
  scale_fill_manual(values = ccc) + 
  labs(x = 'Actual Residual (deg C)', y = 'Predicted Residual (deg C)', fill = '# of Retrievals') +
  ggsave('lowest_uncertainty_partition_predictions_vs_actual.pdf', device = 'pdf', width = 8, height = 6, units = 'in')

```

```{r schematic_diagram_highest_uncertainty, echo = TRUE}

ggplot2::ggplot() +
  geom_histogram(bins = 50, aes(orig_train$SST.resid.SMB[orig_train$rule_numb == 3])) +
  labs(x = 'Actual Residual (deg C)', y = '# of Retrievals') +
  xlim(-4, 2) +
  ylim(0, 675) +
  annotate('text', x = .67, y = 650, label = 'Size: 8854 Retrievals', size = 8) +
  annotate('text', x = .67, y = 610, label = 'Median: -1.16 deg C', size = 8) +
  annotate('text', x = .67, y = 570, label = 'IQR: 1.47 deg C', size = 8) +
  annotate('text', x = .67, y = 530, label = 'Uncertainty: 0.521 deg C', size = 8) +
  ggsave('highest_uncertainty_partition_histogram.pdf', device = 'pdf', width = 8, height = 6, units = 'in') +
  ggsave('highest_uncertainty_partition_histogram.png', device = 'png', width = 8, height = 6, units = 'in')

ccc <- RColorBrewer::brewer.pal(n = 9, 'YlOrRd')
ccc <- ccc[3:9]
breaks <- c(0, 10, 25, 50, 100, 500, 1000, 2500, Inf)
ccc <- colorRampPalette(ccc)(length(breaks) - 1)

rrr <- data.frame(X = orig_train$SST.resid.SMB[orig_train$rule_numb == 3], Y = Cubist_rules_train_vals[orig_train$rule_numb == 3])

ggplot2::ggplot(data = rrr, aes(x = X, y = Y, fill = cut(..count.., c(0, 10, 25, 50, 100, 500, 1000, 2500, Inf)))) +
  geom_bin2d(bins = 75) +
  geom_abline(slope = 1, intercept = 0, col = 'black') +
  scale_fill_manual(values = ccc) + 
  labs(x = 'Actual Residual (deg C)', y = 'Predicted Residual (deg C)', fill = '# of Retrievals') +
  ggsave('highest_uncertainty_partition_predictions_vs_actual.pdf', device = 'pdf', width = 8, height = 6, units = 'in')

```


```{r assign_uncertainties, echo = TRUE}

orig_b <- rbind(orig_train, orig_test)
orig_b$uncertainty <- rep(NA, nrow(orig_b))

for (row_num in 1:nrow(orig_b)) {
  orig_b$uncertainty[row_num] <- RMSE_partition_train[orig_b$rule_numb[row_num]]
  #cat(row_num, '\n')
}

# Break back into train and test again
orig_train <- orig_b[1:nrow(orig_train), ]
orig_test <- orig_b[(nrow(orig_train) + 1):nrow(orig_b), ]

```

```{r plot_uncertainties, echo = TRUE}

ccc <- RColorBrewer::brewer.pal(n = 9, 'YlOrRd')
ccc <- ccc[3:9]
breaks <- c(10, 50, 100, 500, 1000, 2500, 5000, Inf)

mmm <- data.frame(X = Cubist_rules_test_vals, Y = orig_test$uncertainty)
mmm$error <- mmm$X - orig_test$SST.resid.SMB

means_train <- tapply(orig_train$SST.resid.SMB, orig_train$rule_numb, mean)
IQR_error_train <- tapply(orig_train$error, orig_train$rule_numb, IQR)
partition_explore <- data.frame(medians = medians_train, uncertainty = RMSE_partition_train, means = means_train, IQR_error = IQR_error_train)

ccc <- colorRampPalette(ccc)(length(breaks) - 1)

ggplot2::ggplot() +
  geom_bin2d(data = mmm, aes(error, Y, fill = cut(..count.., c(10, 50, 100, 500, 1000, 2500, 5000, Inf))), bins = 100) +
  geom_line(aes(partition_explore$IQR_error, partition_explore$uncertainty)) +
  geom_line(aes(-partition_explore$IQR_error, partition_explore$uncertainty)) +
  scale_fill_manual(values = ccc) +
  labs(x = 'Actual Error', y = 'Predicted Uncertainty', fill = '# of Retrievals') +
  ggsave('Cubist_predictions_vs_uncertainty_2d_histogram.pdf', device = 'pdf', width = 8, height = 6, units = 'in')

```

```{r evaluate_uncertainties, echo = TRUE}

in_range_train <- ifelse(Cubist_rules_train_vals + orig_train$uncertainty >= orig_train$SST.resid.SMB & Cubist_rules_train_vals - orig_train$uncertainty <= orig_train$SST.resid.SMB, TRUE, FALSE)

in_range_test <- ifelse(Cubist_rules_test_vals + orig_test$uncertainty >= orig_test$SST.resid.SMB & Cubist_rules_test_vals - orig_test$uncertainty <= orig_test$SST.resid.SMB, TRUE, FALSE)

in_range_RMSE_train <- ifelse(Cubist_rules_train_vals + RMSE_test_cubist >= orig_train$SST.resid.SMB & Cubist_rules_train_vals - RMSE_test_cubist <= orig_train$SST.resid.SMB, TRUE, FALSE)

in_range_RMSE_test <- ifelse(Cubist_rules_test_vals + RMSE_test_cubist >= orig_test$SST.resid.SMB & Cubist_rules_test_vals - RMSE_test_cubist <= orig_test$SST.resid.SMB, TRUE, FALSE)

```

```{r Cubist_variable_importance, echo=TRUE}

variable_names_long <- c('Except\nResidual Temperature Deficit Estimate',
                        'Except\nScaled Channel Difference',
                        'Except\nSatellite Zenith Angle',
                        'Except\nSD of T_11',
                        'Except\nLatitude',
                        'Except\nMonth',
                        'Except\nReference SST')

variable_names_abbrev <- c('td_resid',
                           'x2',
                           'satz',
                           'sd11',
                           'lat',
                           'month',
                           'ref_SST')

empty <- c(0, 0, 0, 0, 0, 0, 0)
RMSE_without <- data.frame(variable_names_long = variable_names_long, variable_names_abbrev = variable_names_abbrev, RMSE = empty)

for (variable_num in 1:nrow(RMSE_without)) {
  iii <- c(1, 2, 3, 4, 5, 6, 7)
  iii <- iii[!iii %in% variable_num]
  variables_temp <- variable_names_abbrev[iii]
  ppp <- orig_train[, c(variables_temp, 'SST.resid.SMB')]
  
  Cubist_var_imp <- Cubist::cubist(x = ppp[, variables_temp], y = ppp$SST.resid.SMB,
                                   committees = 1, 
                                   control = Cubist::cubistControl(rules = 28,
                                                                   unbiased = FALSE,
                                                                   extrapolation = 100,
                                                                   label = 'SST Residual',
                                                                   seed = 108))
    
  # Create test set predictions
  Cubist_predictions_test_temp <- stats::predict(object = Cubist_var_imp, na.action = na.pass, neighbors = 8, newdata = orig_test)
  
  # Now compute RMSE
  RMSE_temp <- caret::RMSE(orig_test$SST.resid.SMB, Cubist_predictions_test_temp)
  
  RMSE_without[variable_num, 'RMSE'] <- RMSE_temp

}

# 0.3795971 is the RMSE on the test set with ALL variables (from above)
RMSE_without$RMSE_incr <- RMSE_without$RMSE - 0.3795971

RMSE_without$variable_names_long <- reorder(RMSE_without$variable_names_long, -RMSE_without$RMSE)

ggplot2::ggplot(data = RMSE_without, aes(x = variable_names_long, y = RMSE_incr)) +
  geom_bar(stat = 'identity') +
  theme(axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5)) +
  labs(x = 'Feature', y = 'Increase in RMSE (deg C)') +
  ggsave('variable_importance_RMSE_Cubist.pdf', device = 'pdf', width = 8, height = 6, units = 'in') +
  ggsave('variable_importance_RMSE_Cubist.png', device = 'png', width = 8, height = 6, units = 'in')
```

